{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulation methods: Monte Carlo\n",
    "\n",
    "In this notebook, we present a simple example of a Monte Carlo simulation. We will use the `numpy` package to generate random numbers and the `matplotlib` package to plot the results.\n",
    "We will also use the `seaborn` package to make the plots look nicer and plot confidence intervals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import scipy.optimize as opt\n",
    "%matplotlib inline\n",
    "compute_error = False"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A first example\n",
    "\n",
    "We consider $X$ a random variable on $\\{0;1;-1\\}$ with probabilities:\n",
    "1. $\\mathbb P(X=-1)=\\frac{1}{3}$.\n",
    "2. $\\mathbb P(X=0)=\\frac{1}{6}$.\n",
    "3. $\\mathbb P(X=1)=\\frac{1}{2}$.\n",
    "\n",
    "We also consider $Y$ another random variable such that $\\mathbb P(Y=0)=\\frac45$."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Equaling the expectations\n",
    "We first want to have $\\mathbb E[X]=\\mathbb E[Y]$.\n",
    "We are going to compute $\\mathbb P(Y=-1)$ and $\\mathbb P(Y=1)$ such that we have this equality.\n",
    "$$\\mathbb E[X]=\\mathbb E[Y]\\iff \\sum_{x\\in\\{-1;0;1\\}}x\\mathbb P(X=x)=\\sum_{y\\in\\{-1;0;1\\}}y\\mathbb P(Y=y)\\iff -\\frac{1}{3}+\\frac{1}{2}=\\mathbb P(Y=1)-\\mathbb P(Y=-1)$$\n",
    "Then, we have: $$\\mathbb P(Y=1)-\\mathbb P(Y=-1)=\\frac{1}{6}$$ and $$\\mathbb P(Y=1)+\\mathbb P(Y=-1)=\\frac15$$\n",
    "Therefore, we have:\n",
    "$$\\mathbb P(Y=1)=\\frac{11}{60}\\qquad \\text{and}\\qquad \\mathbb P(Y=-1)=\\frac{1}{60}$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing and comparing variances\n",
    "\n",
    "We now want to compute the variance of $X$ and $Y$ and compare them.\n",
    "To do so, we are going to use the following formula:\n",
    "$$\\mathbb V[X]=\\mathbb E[X^2]-\\mathbb E[X]^2$$\n",
    "We have:\n",
    "$$\\mathbb E[X^2]=\\frac{1}{3}+\\frac{1}{2}=\\frac{5}{6}$$\n",
    "$$\\mathbb E[X]=\\frac12-\\frac13=\\frac{1}{6}$$\n",
    "We need the same for $Y$:\n",
    "$$\\mathbb E[Y^2]=\\frac{1}{60}+\\frac{11}{60}=\\frac{1}{5}$$\n",
    "$$\\mathbb E[Y]=-\\frac{1}{60}+\\frac{11}{60}=\\frac{1}{6}$$\n",
    "We can now compute the variances:\n",
    "$$\\mathbb V[X]=\\frac{5}{6}-\\left(-\\frac{1}{6}\\right)^2=\\frac{29}{36}$$\n",
    "$$\\mathbb V[Y]=\\frac{1}{5}-\\left(-\\frac{10}{60}\\right)^2=\\frac{31}{180}$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimental comparison\n",
    "We now wish to compare the theoretical and experimental expectancies and variances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampleX(n):\n",
    "    A = np.zeros(n)\n",
    "    for i in range(n):\n",
    "        u = np.random.random()\n",
    "        if u <= 1/3:\n",
    "            A[i] = -1\n",
    "        elif u <= 1/2:\n",
    "            A[i] = 0\n",
    "        else:\n",
    "            A[i] = 1\n",
    "    return A\n",
    "\n",
    "\n",
    "def sampleY(n):\n",
    "    A = np.zeros(n)\n",
    "    for i in range(n):\n",
    "        u = np.random.random()\n",
    "        if u <= 1/60:\n",
    "            A[i] = -1\n",
    "        elif u <= 1/60 + 4/5:\n",
    "            A[i] = 0\n",
    "        else:\n",
    "            A[i] = 1\n",
    "    return A"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the previous functions, we can compute the mean of $X$ and $Y$ and compare them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1000\n",
    "X = [np.mean(sampleX(i)) for i in range(1, N)]\n",
    "Y = [np.mean(sampleY(i)) for i in range(1, N)]\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.scatter(range(1, N), X, label='X')\n",
    "plt.scatter(range(1, N), Y, label='Y')\n",
    "plt.plot(range(1, N), [1/6 for _ in range(1, N)], label='E', color='red')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We therefore notice that both mean are quite equal, when excluding the first value.\n",
    "\n",
    "Now, we are going to compare the variances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 7))\n",
    "plt.scatter(range(1, N), [np.std(sampleX(i)) **\n",
    "            2 for i in range(1, N)], label='X')\n",
    "plt.plot(range(1, N), [29/36 for _ in range(1, N)], label='V[X]', color='red')\n",
    "plt.scatter(range(1, N), [np.std(sampleY(i)) **\n",
    "            2 for i in range(1, 1000)], label='Y')\n",
    "plt.plot(range(1, N), [31/180 for _ in range(1, N)],\n",
    "         label='V[Y]', color='green')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These two have the same expected value, but the variance of $X$ is much higher than the variance of $Y$."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confidence intervals\n",
    "Now, we are going to compute the confidence intervals, and compare them.\n",
    "We will take a threshold of 0.05."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 7))\n",
    "plt.scatter(range(1, N), X, label='X', color='yellow')\n",
    "confX = np.array([1.96 * np.std(sampleX(i)) / np.sqrt(i) for i in range(1, N)])\n",
    "plt.title(\"Confidence interval for X\")\n",
    "plt.fill_between(range(1, N), X-confX, X+confX, color='b',\n",
    "                 alpha=.3, label='0.95 confidence interval')\n",
    "plt.plot(range(1, N), [1/6 for _ in range(1, N)], label='E[X]', color='red')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.title(\"Confidence interval for Y\")\n",
    "plt.scatter(range(1, N), Y, label='Y', color='yellow')\n",
    "confY = np.array([1.96 * np.std(sampleY(i)) / np.sqrt(i) for i in range(1, N)])\n",
    "plt.fill_between(range(1, N), Y-confY, Y+confY, color='b',\n",
    "                 alpha=.3, label='0.95 confidence interval')\n",
    "plt.plot(range(1, N), [1/6 for _ in range(1, N)], label='E[Y]', color='red')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We notice that the confidence intervals are going smaller when $n$ increases.\n",
    "This can be used to determine any estimation error."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimation error\n",
    "\n",
    "Using Python, we are going to numerically compute the estimation error and find the value of $n$ such that the estimation error is less than $0.01$.\n",
    "Mathematically, this error is defined as, with a confidence threshold of $95\\,\\%$:\n",
    "$$\\sigma_{\\bar x}=1.96\\frac{\\sigma_x}{\\sqrt{n}}$$\n",
    "Therefore, we are going to generate samples of size $n\\geq 100$ and this value until it is less than $0.01$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if compute_error:\n",
    "    n = 100  # Lower bound for N0\n",
    "    X = sampleX(n)\n",
    "\n",
    "    while 1.96 * np.std(X) / np.sqrt(len(X)) > 0.01:\n",
    "        n += 1\n",
    "        X = sampleX(n)\n",
    "    print(\"N0 for X is\", n)\n",
    "\n",
    "    n = 100  # Lower bound for N0\n",
    "    Y = sampleY(n)\n",
    "\n",
    "    while 1.96 * np.std(Y) / np.sqrt(len(Y)) > 0.01:\n",
    "        n += 1\n",
    "        Y = sampleY(n)\n",
    "    print(\"N0 for Y is\", n)\n",
    "else: print(\"Computing error has been disabled to compute results faster.\\nTo change it, switch the compute_error variable to \\\"True\\\" in the first code part.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we seek to compute the estimation error with a threshold of $0.001$.\n",
    "To do so, we will first compute the theoretical estimation error then begin with a size that will be close to this value.\n",
    "If we don't do that, as the convergence is in $\\mathrm O(n^{-1/2})$, we will have to wait a long time to get a good estimation.\n",
    "\n",
    "We want to have a threshold of $0.001$ so $\\sigma_{\\bar x}=\\frac{\\sigma_x}{\\sqrt{n}}\\leq 0.001$ and $\\sigma_{\\bar y}=\\frac{\\sigma_x}{\\sqrt{n}}\\leq 0.001$, with the same confidence threshold.\n",
    "We already know that:\n",
    "$$\\mathbb V[X]=\\frac{29}{36}\\qquad \\text{and}\\qquad \\mathbb V[Y]=\\frac{31}{180}$$\n",
    "so we have\n",
    "$$\\sigma_x=\\sqrt{\\frac{29}{36}}\\approx 0.89\\qquad \\text{and}\\qquad \\sigma_y=\\sqrt{\\frac{31}{180}}\\approx 0.41$$\n",
    "We can now find the value of $n$ such that $\\sigma_{\\bar x}\\leq 0.001$ and $\\sigma_{\\bar y}\\leq 0.001$, which is:\n",
    "$$\\boxed{n_x\\geq \\frac{1.96^2\\sigma_x^2}{0.001^2}=\\frac{1.96^2\\cdot0.89^2}{0.001^2}\\approx 3\\times10^6}$$\n",
    "and\n",
    "$$\\boxed{n_y\\geq \\frac{1.96^2\\sigma_y^2}{0.001^2}=\\frac{1.96^2\\cdot0.41^2}{0.001^2}\\approx 6.46\\times10^5}$$\n",
    "If we do the same computation with a threshold of $0.01$, we get:\n",
    "$$\\boxed{n_x\\geq \\frac{1.96^2\\sigma_x^2}{0.01^2}=\\frac{1.96^2\\cdot0.89^2}{0.01^2}\\approx 3\\times10^4}$$\n",
    "and\n",
    "$$\\boxed{n_y\\geq \\frac{1.96^2\\sigma_y^2}{0.01^2}=\\frac{1.96^2\\cdot0.41^2}{0.01^2}\\approx 6.46\\times10^3}$$\n",
    "This fits with our previous results.\n",
    "Now, let's see for a threshold of $0.001$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if compute_error:\n",
    "    n = 3 * 10 ** 6  # Lower bound for N0\n",
    "    X = sampleX(n)\n",
    "\n",
    "    while 1.96 * np.std(X) / np.sqrt(len(X)) > 0.001:\n",
    "        n += 1000\n",
    "        X = sampleX(n)\n",
    "    print(\"N0 for X is\", n)\n",
    "\n",
    "    n = 5 * 10 ** 5  # Lower bound for N0\n",
    "    Y = sampleX(n)\n",
    "\n",
    "    while 1.96 * np.std(Y) / np.sqrt(len(Y)) > 0.001:\n",
    "        n += 1000\n",
    "        Y = sampleX(n)\n",
    "    print(\"N0 for Y is\", n)\n",
    "else: print(\"Computing error has been disabled to compute results faster.\\nTo change it, switch the compute_error variable to \\\"True\\\" in the first code part.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normal law and Monte-Carlo simulation\n",
    "We now consider $(\\Omega,\\mathcal F,\\mathbb P)$ a probability space\n",
    "and $(X_k)_{0\\leq k\\leq n}$ a sequence of random variables such that:\n",
    "$$\\forall k\\in\\{0;1;\\ldots;n\\},\\qquad X_k=x_0\\exp\\left(\\left(\\mu-\\frac{\\sigma^2}2\\right)\\frac kn+\\sigma\\sqrt{\\frac kn}Y_k\\right)$$\n",
    "with $\\mu>0$, $\\sigma>0$ and $Y_k$ i.i.d. standard normal random variables.\n",
    "\n",
    "Let $(\\mathcal G_k)_{0\\leq k\\leq n}$ be the filtration generated by $(Y_k)_{0\\leq k\\leq n}$ with $\\mathcal G_0=\\{\\emptyset,\\Omega\\}$.\n",
    "Let $0<a<b$, $h(x)=\\min\\{|x-a|;|x-b|\\}$ and $\\tau=\\inf\\{k\\geq 0\\mid X_k\\notin[a;b]\\}$.\n",
    "To make things easier, we assume that $\\mu=0$."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing the theoretical expectancy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numerical application\n",
    "We are now going to use the previous result to compute the expectancy of $h(X_n)$.\n",
    "For that, we will consider:\n",
    "- $n=30$.\n",
    "- $x_0=20$.\n",
    "- $\\sigma=0.9$.\n",
    "- $a=8$.\n",
    "- $b=36$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 30\n",
    "x0 = 20\n",
    "sigma = 0.9\n",
    "a = 8\n",
    "b = 36\n",
    "\n",
    "def omega(x, k=n):\n",
    "    return (np.log(x/x0)-k*(-sigma**2/2)/n)/(sigma*np.sqrt(k/n))\n",
    "\n",
    "def Phi(x):\n",
    "    return stats.norm.cdf(x, loc=0, scale=1)\n",
    "\n",
    "bpart = Phi(Phi(omega(b)) - omega((a+b)/2))\n",
    "apart = Phi(omega((a+b)/2)) - Phi(omega(a))\n",
    "xpart = 2 * Phi(omega((a+b)/2) - sigma) - \\\n",
    "    Phi(omega(b) - sigma) - Phi(omega(a) - sigma)\n",
    "\n",
    "Lambda = b * bpart - a * apart + x0 * xpart\n",
    "p = Lambda\n",
    "for i in range(1, n):\n",
    "    p *= (Phi((omega(b, i))) - Phi(omega(a, i)))\n",
    "\n",
    "print(f\"The expectancy in this situation is {p}.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monte-Carlo simulation\n",
    "We willm now use the Monte-Carlo simulation process to numerically compute the expectancy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10 ** 4  # Number of simulations\n",
    "# n is the size of the sample\n",
    "\n",
    "def generateSample():\n",
    "    Y = np.random.normal(size=n)\n",
    "    X = []\n",
    "    for k in range(n):\n",
    "        X.append(x0 * (-sigma ** 2 / 2) * k / n + sigma * np.sqrt(k / n) * Y[i])\n",
    "    return np.array(X)\n",
    "\n",
    "means = []\n",
    "X=range(n)\n",
    "plt.figure(figsize=(10, 7))\n",
    "for _ in range(N):\n",
    "    sample = generateSample()\n",
    "    tau = n + 1\n",
    "    for i in range(n):\n",
    "        if sample[i] < a or sample[i] > b:\n",
    "            tau = i\n",
    "            break\n",
    "    hsample = np.array([(np.abs(x - a) if np.abs(x - a) < np.abs(x-b)\n",
    "                       else np.abs(x-b)) if tau > n else 0 for x in sample])\n",
    "    means.append(np.mean(sample))\n",
    "    if N % 2000 == 0:\n",
    "        plt.plot(X, sample)\n",
    "\n",
    "print(f\"The Monte-Carlo simulation gives an estimate of {np.mean(means)}.\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recursive model\n",
    "We are now doing the same with a recursive model:\n",
    "$$\\forall k\\in\\{0;1;\\ldots;n\\},\\qquad X_{k+1}=X_k\\exp\\left(\\frac1n\\left(\\mu-\\frac{\\sigma^2}{2}\\right)+\\sigma\\sqrt{\\frac1n}Y_{k+1}\\right)$$\n",
    "with $X_0=x_0$, $\\mu>0$, $\\sigma>0$ and $Y_k$ i.i.d. standard normal random variables.\n",
    "\n",
    "For this model, we will only make a numerical simulation: computing the theoretical expectancy would result in a recursive formula."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10 ** 4  # Number of simulations\n",
    "# n is the size of the sample\n",
    "\n",
    "def generateSample():\n",
    "    Y = np.random.normal(size=n)\n",
    "    X = [x0]\n",
    "    for i in range(1, n):\n",
    "        X.append(X[i-1]*np.exp((-sigma**2)/2)/n+sigma*np.sqrt(1/n)*Y[i])\n",
    "    return np.array(X)\n",
    "\n",
    "means = []\n",
    "X=range(n)\n",
    "plt.figure(figsize=(10, 7))\n",
    "for _ in range(N):\n",
    "    sample = generateSample()\n",
    "    tau = n + 1\n",
    "    for i in range(n):\n",
    "        if sample[i] < a or sample[i] > b:\n",
    "            tau = i\n",
    "            break\n",
    "    hsample = np.array([(np.abs(x - a) if np.abs(x - a) < np.abs(x-b)\n",
    "                       else np.abs(x-b)) if tau > n else 0 for x in sample])\n",
    "    means.append(np.mean(sample))\n",
    "    if N % 2000 == 0:\n",
    "        plt.plot(X, sample)\n",
    "\n",
    "print(f\"The Monte-Carlo simulation gives an estimate of {np.mean(means)}.\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We notice that the output value fits with the plot.\n",
    "\n",
    "### Confidence intervals\n",
    "\n",
    "We now want to compute the confidence intervals for the previous result.\n",
    "1. For $\\sigma=0.9$, we have:\n",
    "$$I=\\left[0.06-1.96\\frac{0.9}{\\sqrt{30}};0.06+1.96\\frac{0.9}{\\sqrt{30}}\\right]\\approx [0.03;0.09]$$\n",
    "2. For $\\sigma=0.4$, we have:\n",
    "$$I=\\left[0.06-1.96\\frac{0.4}{\\sqrt{30}};0.06+1.96\\frac{0.4}{\\sqrt{30}}\\right]\\approx [0.05;0.07]$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison between Monte-Carlo naive and importance sampling methods\n",
    "We now consider $X\\sim\\mathcal N(0,1)$ and $g:x\\longmapsto x^21_{\\{x\\geq 0.5\\}}$. This function has the following representation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = lambda x : x ** 2 if x >= 0.5 else 0\n",
    "X=np.linspace(-2,2,1000)\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.plot(X, [g(x) for x in X],label='g')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to compare on $\\mathbb E[g(X)]$.\n",
    "### Monte-Carlo method\n",
    "We are going to generate a sample of size $10000$ and compute apply this method on the sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.random.normal(size=n)\n",
    "gX = np.array([g(x) for x in X])\n",
    "print(f\"The expectation of g(X) is {np.mean(gX)}.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confidence intervals\n",
    "We now want to visualize the confidence intervals for the previous result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=range(1,10000)\n",
    "means = []\n",
    "std = []\n",
    "for x in X:\n",
    "    sample = np.random.normal(size=x)\n",
    "    gX = np.array([g(x) for x in sample])\n",
    "    means.append(np.mean(gX))\n",
    "    std.append(np.std(gX))\n",
    "\n",
    "means=np.array(means)\n",
    "std = np.array(std)\n",
    "\n",
    "plt.plot(X, means, label='E[g(X)]')\n",
    "conf = np.array([1.96 * std[i - 1] / np.sqrt(i) for i in X])\n",
    "plt.fill_between(X, means - conf, means + conf, color='b',\n",
    "                 alpha=.3, label='0.95 confidence interval')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We notice that, for a threshold of $0.05$, all values are in the intervals."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stuyding a group of normal variables\n",
    "\n",
    "We consider $A=[0;6]$ and $\\{Z^\\mu\\mid \\mu\\in A\\}$ such that $Z^\\mu\\sim\\mathcal N(\\mu,1)$.\n",
    "First, we want to know which function $\\psi$ allows us to have $\\mathbb E[g(X)]=\\mathbb E[\\psi(Z^\\mu)]$.\n",
    "The function $\\psi:x\\longmapsto (x-\\mu)^21_{\\{x\\geq 0.5\\}}$ fits.\n",
    "\n",
    "Here are some plots for this function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.linspace(0,2,1000)\n",
    "\n",
    "def psi(x,mu):\n",
    "    if x >= 0.5: return (x - mu) ** 2\n",
    "    return 0.0\n",
    "\n",
    "plt.figure(figsize=(10,7))\n",
    "for _ in range(5):\n",
    "    mu = np.random.random() * 6\n",
    "    plt.plot(X,[psi(x,mu) for x in X],label = \"mu = \" + str(round(mu,ndigits=2)))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we assume that $\\mu=0.1$.\n",
    "For $N=1000$ then $N=10000$, we seek to estimate $\\mathbb E[g(X)]$ using the importance sampling method.\n",
    "To do so, we will use a $N$-sized sample of $Z^\\mu$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using the Robbins-Monro algorithm\n",
    "mu = 0.1\n",
    "for N in (1000,10000):\n",
    "    sample = np.random.normal(loc = mu, scale = 1, size = N)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6e65e619eafabfef1bc0e716517d0e2fc7993b41bb7995afd572552e4bbdc003"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
